{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Система прогнозирования прибыльности и выбора локаций для бурения скважин в компании «ГлавРосГосНефть»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добывающая компания «ГлавРосГосНефть» стремится повысить эффективность добычи нефти, определяя регионы с максимальным потенциалом прибыли. Для этого необходимо разработать систему, которая позволит анализировать данные геологоразведки, прогнозировать объём запасов нефти и принимать решения о бурении скважин в наиболее выгодных точках.\n",
    "\n",
    "- **Цели и задачи проекта:**\n",
    "\n",
    "    - **Прогнозирование запасов нефти**: Создание модели машинного обучения, способной точно оценивать объём нефти в скважинах на основе характеристик месторождений. Это поможет отбирать перспективные точки для разработки.  \n",
    "\n",
    "    - **Оценка прибыли и рисков**: Анализ доходности бурения с учётом бюджета и рыночных условий. Использование техники Bootstrap для расчёта распределения прибыли, определения риска убытков и обоснования решений.  \n",
    "\n",
    "    - **Оптимизация выбора региона**: На основе модели выбрать регион с наибольшей суммарной прибылью и минимальной вероятностью убытков, соблюдая установленные бизнес-ограничения.  \n",
    "\n",
    "    - **Ключевые требования к системе**:  \n",
    "        - Высокая точность прогнозов объёма запасов.  \n",
    "        - Возможность оценки рисков и прибыли для каждого региона.  \n",
    "        - Удобная интеграция модели в текущие бизнес-процессы компании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## Импорт и подготовка к работе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from itertools import cycle\n",
    "from pprint import pprint\n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from phik import report\n",
    "import shap\n",
    "from bidict import bidict\n",
    "from category_encoders import (JamesSteinEncoder,\n",
    "                               LeaveOneOutEncoder,\n",
    "                               MEstimateEncoder,\n",
    "                               WOEEncoder)\n",
    "from optuna.visualization import plot_param_importances\n",
    "import plotly\n",
    "from plotly.colors import find_intermediate_color, hex_to_rgb\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import express as px, graph_objects as go\n",
    "from sklearn.base import clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, f_classif\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (MinMaxScaler,\n",
    "                                   OneHotEncoder,\n",
    "                                   OrdinalEncoder,\n",
    "                                   StandardScaler)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MaxAbsScaler, QuantileTransformer, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "optuna_sampler = optuna.samplers.TPESampler(seed=RANDOM_STATE)\n",
    "color_palette = cycle(px.colors.qualitative.Plotly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## Загрузка данных и общая информация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Скачивание датасетов и общая информация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Три таблицы имеет данные о скважинах из трех регионов соответственно и имеет вид: \n",
    "\n",
    "|Поле                               |Описание                                |\n",
    "|-----------------------------------|----------------------------------------|\n",
    "|id                                 |Уникальный идентификатор скважины       |\n",
    "|f0                                 |Параметр 1                              |\n",
    "|f1                                 |Параметр 2                              |\n",
    "|f2                                 |Параметр 3                              |\n",
    "|product                            |Объём запасов в скважине (тыс. баррелей)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **`geo_data_0.csv`** (Первый регион)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    regions_wells_1 = pd.read_csv('geo_data_0.csv', delimiter=',')\n",
    "except:\n",
    "    regions_wells_1 = pd.read_csv('/datasets/geo_data_0.csv', delimiter=',')\n",
    "display(regions_wells_1.head())\n",
    "regions_wells_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **`geo_data_1.csv`** (Второй регион)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    regions_wells_2 = pd.read_csv('geo_data_1.csv', delimiter=',')\n",
    "except:\n",
    "    regions_wells_2 = pd.read_csv('/datasets/geo_data_1.csv', delimiter=',')\n",
    "display(regions_wells_2.head())\n",
    "regions_wells_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **`geo_data_2.csv`** (Третий регион)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    regions_wells_3 = pd.read_csv('geo_data_2.csv', delimiter=',')\n",
    "except:\n",
    "    regions_wells_3 = pd.read_csv('/datasets/geo_data_2.csv', delimiter=',')\n",
    "display(regions_wells_3.head())\n",
    "regions_wells_3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `regions_wells_1` (`geo_data_0.csv`)\n",
    "    - Содержит данные о скважинах первого региона.\n",
    "    - Всего 100,000 строк.\n",
    "    - Пропущенных значений нет.\n",
    "    - 3 количественных признака: `f0`, `f1`, `f2`, `product`.\n",
    "    - 1 категориальный признак: `id`.\n",
    "    - Типы данных верные.\n",
    "\n",
    "- `regions_wells_2` (`geo_data_1.csv`)\n",
    "    - Содержит данные о скважинах первого региона.\n",
    "    - Всего 100,000 строк.\n",
    "    - Пропущенных значений нет.\n",
    "    - 3 количественных признака: `f0`, `f1`, `f2`, `product`.\n",
    "    - 1 категориальный признак: `id`.\n",
    "    - Типы данных верные.\n",
    "\n",
    "- `regions_wells_3` (`geo_data_2.csv`)\n",
    "    - Содержит данные о скважинах первого региона.\n",
    "    - Всего 100,000 строк.\n",
    "    - Пропущенных значений нет.\n",
    "    - 3 количественных признака: `f0`, `f1`, `f2`, `product`.\n",
    "    - 1 категориальный признак: `id`.\n",
    "    - Типы данных верные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Наименовывание столбцов датафреймов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все столбцы названы корректно, однако для удобства переименуем таргет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_wells_1 = regions_wells_1.rename(columns={'product': 'well_reserves_volume'})\n",
    "regions_wells_2 = regions_wells_2.rename(columns={'product': 'well_reserves_volume'})\n",
    "regions_wells_3 = regions_wells_3.rename(columns={'product': 'well_reserves_volume'})\n",
    "\n",
    "columns_translate = bidict({\n",
    "    'id': 'id',\n",
    "    'f0': 'Признак 1',\n",
    "    'f1': 'Признак 2',\n",
    "    'f2': 'Признак 3',\n",
    "    'well_reserves_volume': 'Объем запасов в скважине',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Обработка дубликатов и опечаток"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Явные***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Кол-во явных дубликатов в regions_wells_1:\\t', regions_wells_1.id.duplicated().sum())\n",
    "print('Кол-во явных дубликатов в regions_wells_2:\\t', regions_wells_2.id.duplicated().sum())\n",
    "print('Кол-во явных дубликатов в regions_wells_3:\\t', regions_wells_3.id.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_wells_1 = regions_wells_1.drop_duplicates(subset=['id'])\n",
    "regions_wells_2 = regions_wells_2.drop_duplicates(subset=['id'])\n",
    "regions_wells_3 = regions_wells_3.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явные дубликаты удалены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Неявные***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Кол-во явных дубликатов в regions_wells_1:\\t', regions_wells_1[['f0', 'f1', 'f2', 'well_reserves_volume']].duplicated().sum())\n",
    "print('Кол-во явных дубликатов в regions_wells_2:\\t', regions_wells_2[['f0', 'f1', 'f2', 'well_reserves_volume']].duplicated().sum())\n",
    "print('Кол-во явных дубликатов в regions_wells_3:\\t', regions_wells_3[['f0', 'f1', 'f2', 'well_reserves_volume']].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неявные дубликаты отсутствуют"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Обработка аномальных значений и выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots(data: pd.DataFrame, data_name: str, row: int, cols: int, height: int, weight: int):\n",
    "    fig = make_subplots(rows=row, cols=cols, vertical_spacing=0.07,\n",
    "                        subplot_titles=[columns_translate[name]\n",
    "                                        for name in data.select_dtypes(include=['number']).columns])\n",
    "    for i, column in enumerate(data.select_dtypes(include=['number']).columns):\n",
    "        fig.add_trace(\n",
    "            go.Box(y=data[column], name=''),\n",
    "            row=(i // cols) + 1, col=(i % cols) + 1\n",
    "        )\n",
    "    fig.update_layout(height=height, width=weight, showlegend=False, title=f'График \"Ящик с усами\" для каждой количественной фичи в {data_name}')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplots(regions_wells_1, 'regions_wells_1', row=1, cols=4, height=600, weight=1200)\n",
    "plot_boxplots(regions_wells_2, 'regions_wells_2', row=1, cols=4, height=600, weight=1200)\n",
    "plot_boxplots(regions_wells_3, 'regions_wells_3', row=1, cols=4, height=600, weight=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Математически есть выбросы, однако нельзя их убирать, так как:\n",
    "    1. Они не сильно выбиваются;\n",
    "    2. Из-за незнания что эти столбцы хранят;\n",
    "    3. Может эти выбивающиеся значения и есть скважины с большим кол-вом нефти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Смена индекса датафреймов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_wells_1 = regions_wells_1.set_index('id')\n",
    "regions_wells_2 = regions_wells_2.set_index('id')\n",
    "regions_wells_3 = regions_wells_3.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Удалил неявные дубликаты.\n",
    "- Обработал аномальные значения и выбросы.\n",
    "- Поменял индексы датафреймов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## Анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Функции отрисовок данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_graphis_for_numeric(col: pd.Series, title_text=None, nbinsx=50):\n",
    "    \"\"\"\n",
    "    Функция для построения графиков для числовых данных: гистограммы и диаграммы размаха.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    col : pd.Series\n",
    "        Входные данные в виде столбца (серии) pandas, представляющие числовую переменную.\n",
    "        \n",
    "    nbinsx : int, по умолчанию 50\n",
    "        Количество корзин (bins) для построения гистограммы. Управляет точностью распределения данных по оси x.\n",
    "    \"\"\"\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=('Гистограмма', 'Диаграмма размаха'))\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=col, nbinsx=nbinsx, marker_color='blue', name=col.name),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=columns_translate[col.name], row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Частота', row=1, col=1)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Box(y=col, marker_color='orange', name=''),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.update_yaxes(title_text=columns_translate[col.name], row=1, col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=(title_text if title_text\n",
    "                    else f'Статистические графики по значению <b>{columns_translate[col.name]}</b> (<b>{col.name}</b>)'),\n",
    "        title_x=0.5,\n",
    "        showlegend=False,\n",
    "        width=1200,\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### `regions_wells_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_col in regions_wells_1.select_dtypes(include=['number']).columns:\n",
    "    statistical_graphis_for_numeric(\n",
    "        col=regions_wells_1[num_col],\n",
    "        nbinsx={'f0': 50, 'f1': 50, 'f2': 50, 'well_reserves_volume': 80}[num_col]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### `regions_wells_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_col in regions_wells_2.select_dtypes(include=['number']).columns:\n",
    "    statistical_graphis_for_numeric(\n",
    "        col=regions_wells_2[num_col],\n",
    "        nbinsx={'f0': 50, 'f1': 50, 'f2': 20, 'well_reserves_volume': 20}[num_col]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### `regions_wells_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_col in regions_wells_3.select_dtypes(include=['number']).columns:\n",
    "    statistical_graphis_for_numeric(\n",
    "        col=regions_wells_3[num_col],\n",
    "        nbinsx={'f0': 50, 'f1': 50, 'f2': 50, 'well_reserves_volume': 80}[num_col]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Данные многомодально распределены.\n",
    "- Некоторые признаки (причем в зависимости от скважин) дискретны.\n",
    "- Обязательно стоит рассмотреть корреляцию между признаками, потому что некоторые признаки как будто дополняют друг друга (к примеру признаки 1 и 2 из первой скважины)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## Корреляционный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_binned_df(data: pd.DataFrame, bins=100):\n",
    "    binned_data = data.copy()\n",
    "    for num_col in data.select_dtypes(include=['number']).columns:\n",
    "        binned_data[num_col] = pd.cut(binned_data[num_col], bins, labels=False)\n",
    "    return binned_data\n",
    "\n",
    "\n",
    "def corr_and_significance_matrices(data: pd.DataFrame, data_name: str, interval_cols: list[str] = None):\n",
    "    display(px.imshow(\n",
    "        data.rename(\n",
    "            columns=columns_translate\n",
    "        ).phik_matrix(interval_cols), \n",
    "        text_auto='.2f',\n",
    "        color_continuous_scale='oranges',\n",
    "        title=f'Матрица корреляции для <b>{data_name}</b>'\n",
    "    ).update_layout(\n",
    "        width=800,\n",
    "        height=800,\n",
    "        title_font_size=20,\n",
    "        font=dict(size=14)\n",
    "    ))\n",
    "    display(px.imshow(\n",
    "        data.rename(\n",
    "            columns=columns_translate\n",
    "        ).significance_matrix(interval_cols),\n",
    "        text_auto='.2f',\n",
    "        color_continuous_scale='oranges',\n",
    "        title=f'Матрица значимости для <b>{data_name}</b>'\n",
    "    ).update_layout(\n",
    "        width=800,\n",
    "        height=800,\n",
    "        title_font_size=20,\n",
    "        font=dict(size=14)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### `regions_wells_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_and_significance_matrices(self_binned_df(regions_wells_1), 'regions_wells_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### `regions_wells_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_and_significance_matrices(self_binned_df(regions_wells_2), 'regions_wells_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### `regions_wells_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_and_significance_matrices(self_binned_df(regions_wells_3), 'regions_wells_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Корреляция с `Объем запасов в скважине`|Первый регион|Второй регион|Третий регион|\n",
    "|---------------------------------------|-------------|-------------|-------------|\n",
    "|Признак 1                              |слабая       |умеренная    |слабая       |\n",
    "|Признак 2                              |слабая       |слабая       |слабая       |\n",
    "|Признак 3                              |умеренная    |сильная      |умеренная    |\n",
    "\n",
    "- Матрица значимости во всех случаех показывает аналогичные результаты.\n",
    "- Стоит проверить признаки на мультиколлинеарность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Проверка на мультиколлинеарность через VIF*\n",
    "\n",
    "$VIF = \\frac{1}{1-R^2}$\n",
    "- Если $VIF ≈ 1$: мультиколлинеарности нет.\n",
    "- Если  $5 ≤ VIF < 10$: возможна умеренная мультиколлинеарность.\n",
    "- Если  $VIF ≥ 10$: сильная мультиколлинеарность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    regions_wells = [regions_wells_1, regions_wells_2, regions_wells_3][i]\n",
    "    X = add_constant(regions_wells.drop('well_reserves_volume', axis=1))\n",
    "    vif[f'regions_wells_{i}'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "else:\n",
    "    vif['features'] = X.columns\n",
    "    vif = vif.set_index('features')\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Мультиколлинеарность между признаками отсутствует"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Корреляция с целевым признаком**:\n",
    "    - `Признак 1` умеет умеренную корреляцию во втором регионе и слабую в остальных.\n",
    "    - `Признак 2` слабо коррелирует во всех регионах.\n",
    "    - `Признак 3` стабильно показывает среднее-высокое значение во всех регионах.\n",
    "\n",
    "- **Мультиколлинеарность**:\n",
    "    - Среди признаков не наблюдается мультиколлинеарность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Оценка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_perfomance(*results, model_names: list[str]):\n",
    "    \"\"\"\n",
    "    Функция для визуализации результатов отбора признаков с использованием mse или средней точности теста для различных моделей.\n",
    "    Создает график, показывающий зависимость mse (или точности) моделей от количества выбранных признаков.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    *results : dict\n",
    "        - `dict`, содержащий результаты кросс-валидации модели, включая ключ 'mean_test_score' для средней точности модели.\n",
    "\n",
    "    model_names : list of str\n",
    "        Список с именами моделей, которые соответствуют каждому из результатов.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "    for i, result in enumerate(results, start=1):\n",
    "        num_features = np.arange(1, len(result['mean_test_score']) + 1)\n",
    "        mean_test_scores = result['mean_test_score']\n",
    "        fig.add_trace(go.Scatter(x=num_features,\n",
    "                                    y=mean_test_scores,\n",
    "                                    mode='lines+markers',\n",
    "                                    name=model_names[i-1],\n",
    "                                    legendgroup=str(i),\n",
    "                                    legendgrouptitle=dict(text=f'{model_names[i-1]}')))\n",
    "\n",
    "        max_index = np.argmax(mean_test_scores)\n",
    "        fig.add_trace(go.Scatter(x=[num_features[max_index]],\n",
    "                                    y=[mean_test_scores[max_index]],\n",
    "                                    mode='markers',\n",
    "                                    marker=dict(color='red', size=10),\n",
    "                                    showlegend=False,\n",
    "                                    name=model_names[i-1],\n",
    "                                    legendgroup=str(i),\n",
    "                                    legendgrouptitle=dict(text=f'{model_names[i-1]}')))\n",
    "    fig.update_layout(\n",
    "        title_text='MSE моделей в зависимости от числа признаков',\n",
    "        xaxis_title='Число признаков',\n",
    "        yaxis_title='mse',\n",
    "        showlegend=True\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### <a id='toc1_8_2_'></a>[Пайплайн](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pipepline_reg(numerical_columns: list[str]) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Функция для создания пайплайна регрессии с различными методами предварительной обработки данных и отбором признаков.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    numerical_columns : list of str\n",
    "        Список названий числовых признаков.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pipeline\n",
    "        Возвращает объект `Pipeline`, который включает в себя этапы предварительной обработки и этап отбора признаков.\n",
    "    \"\"\"\n",
    "    numerical_preprocessor = Pipeline(\n",
    "        steps=[('imputer', 'passthrough'),\n",
    "               ('scaler', 'passthrough')]\n",
    "    )\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [('numerical', numerical_preprocessor, numerical_columns)],\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "    model = RFECV(estimator=LinearRegression(n_jobs=2),\n",
    "                  min_features_to_select=1,\n",
    "                  step=1,\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  n_jobs=5,\n",
    "                  cv=5,\n",
    "                  verbose=0)\n",
    "    return Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Датасеты*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = regions_wells_1.drop('well_reserves_volume', axis=1)\n",
    "y1 = regions_wells_1.well_reserves_volume\n",
    "X_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(X1, y1, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = regions_wells_2.drop('well_reserves_volume', axis=1)\n",
    "y2 = regions_wells_2.well_reserves_volume\n",
    "X_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(X2, y2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = regions_wells_3.drop('well_reserves_volume', axis=1)\n",
    "y3 = regions_wells_3.well_reserves_volume\n",
    "X_train_3, X_val_3, y_train_3, y_val_3 = train_test_split(X3, y3, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### <a id='toc1_8_3_'></a>[Перебор гиперпараметров через optuna](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Определяю перебираемые параметры для препроцессинга*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_params = {\n",
    "    'preprocessor__numerical__scaler': [\n",
    "        MinMaxScaler(),\n",
    "        RobustScaler(),\n",
    "        MaxAbsScaler(),\n",
    "        QuantileTransformer(output_distribution='normal', random_state=RANDOM_STATE),\n",
    "        QuantileTransformer(output_distribution='uniform', random_state=RANDOM_STATE),\n",
    "        PowerTransformer(method='yeo-johnson', standardize=True),\n",
    "        StandardScaler(),\n",
    "    ],\n",
    "    'preprocessor__numerical__imputer': [\n",
    "        SimpleImputer(strategy='median'),\n",
    "        KNNImputer(n_neighbors=5),\n",
    "        IterativeImputer(estimator=DecisionTreeRegressor(random_state=RANDOM_STATE)),\n",
    "        IterativeImputer(estimator=BayesianRidge()),\n",
    "        IterativeImputer(max_iter=20, random_state=RANDOM_STATE),\n",
    "        SimpleImputer(strategy='mean'),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = None, None, None, None\n",
    "pipeline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Определяю функции для перебора гиперпараметров*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial : optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Целевая функция для оптимизации гиперпараметров с использованием библиотеки Optuna.\n",
    "    В этой функции выполняется настройка и обучение модели с использованием предложенных значений гиперпараметров,\n",
    "    а затем оценивается её точность на валидационной выборке.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial : optuna.trial.Trial\n",
    "        Экземпляр объекта `Trial` из библиотеки Optuna, который используется для выбора гиперпараметров.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Оценка модели (например, точность) на валидационной выборке. Если возникает ошибка, пробный эксперимент прерывается.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        param_name: preprocessor_params[param_name][trial.suggest_categorical(param_name, range(0, len(preprocessor_params[param_name])))]\n",
    "        for param_name in preprocessor_params\n",
    "    }\n",
    "    pipeline_temp:Pipeline = clone(pipeline)\n",
    "    pipeline_temp.set_params(**params)\n",
    "    try:\n",
    "        pipeline_temp.fit(X_train, y_train)\n",
    "        return mean_squared_error(y_val, pipeline_temp.predict(X_val), squared=False)\n",
    "    except ValueError as e: # Обработка несовместных параметров\n",
    "        print(e)\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "\n",
    "def get_best_params(best_params):\n",
    "    return {\n",
    "        param: preprocessor_params[param][best_params[param]] if param in preprocessor_params\n",
    "                                                              else best_params[param]\n",
    "        for param in best_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Первый регион"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = X_train_1, y_train_1, X_val_1, y_val_1\n",
    "\n",
    "pipeline = get_pipepline_reg(X_train.select_dtypes(include='number').columns)\n",
    "\n",
    "reg_region_1 = optuna.create_study(direction='minimize', sampler=optuna_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reg_region_1.optimize(objective, n_trials=300, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best precision: {reg_region_1.best_value:.3f}')\n",
    "best_params = get_best_params(reg_region_1.best_params)\n",
    "print('\\nBest parameters:')\n",
    "pprint(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Важность признаков судя по перебору*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(reg_region_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Так как в валидационных данных не было пропусков, то и значимость признака оценить нельзя, поэтому если модель будет далее использоваться, то необходимо сделать искусственные пропуски в валидационном датасете и переобучить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_8_4_2_'></a>[Feature Engineering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Обучим модель на лучших параметрах*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_region_1 = clone(pipeline).set_params(**best_params)\n",
    "reg_region_1.fit(X_train, y_train)\n",
    "reg_region_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_val, reg_region_1.predict(X_val), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*График зависимости качества модели от количества признаков*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_perfomance(reg_region_1.named_steps['model'].cv_results_,\n",
    "                             model_names=['Регион 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Модель показывает хорошие результаты, ROC AUC топ конфигурации является 0.899\n",
    "- Лучшее кол-во признаков это 8\n",
    "- Модель достаточно стабильна относительно кол-ва признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Интерпретация важности признаков через shap*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_transformed = reg_region_1.transform(X_val)\n",
    "final_feature_names = np.array(reg_region_1.get_feature_names_out())\n",
    "explainer = shap.LinearExplainer(reg_region_1.named_steps['model'].estimator_,\n",
    "                                 shap.maskers.Independent(X_val_transformed), \n",
    "                                 feature_names=final_feature_names)\n",
    "shap_values = explainer.shap_values(X_val_transformed)\n",
    "shap.summary_plot(shap_values,\n",
    "                  X_val_transformed,\n",
    "                  feature_names=final_feature_names,\n",
    "                  plot_type='violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- На изображении можно наблюдать все признаки, отобранные RFECV, и их качество по мнению shap\n",
    "- Важными для логистической регресии являются признаки `avg_categories_per_visit`, `pages_per_visit` и `spent_time_prev_month`\n",
    "- При этом эти признаки обратнопропопрциональны таргету. Также их распределение равномерно и не близко к 0, что показывает их большое качество.\n",
    "- Прямопропорционально таргету являются признаки `promotional_purchases` и `unpaid_products_quarter`, что вполне логично."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### <a id='toc1_8_5_'></a>[Дерево решений](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_8_5_1_'></a>[Подбор гиперпараметров](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_pipepline_clf(\n",
    "    feature_selection='RFECV',\n",
    "    numerical_columns=market.select_dtypes(include='number').columns,\n",
    "    categorical_columns=['popular_category'],\n",
    "    categorical_ordered_columns=['service_type', 'allow_notifications']\n",
    ")\n",
    "\n",
    "model_params_cat = {'model__estimator': [DecisionTreeClassifier(random_state=RANDOM_STATE)],\n",
    "                    'model__estimator__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "                    'model__estimator__splitter': ['best', 'random']}\n",
    "model_params_num = {\n",
    "    'model__estimator__max_depth': lambda trial: trial.suggest_int('model__estimator__max_depth', 3, 40),\n",
    "    'model__estimator__min_samples_split': lambda trial: trial.suggest_int('model__estimator__min_samples_split', 2, 20),\n",
    "    'model__estimator__min_samples_leaf': lambda trial: trial.suggest_int('model__estimator__min_samples_leaf', 1, 10)\n",
    "}\n",
    "\n",
    "study_tree = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "study_tree.optimize(objective, n_trials=300, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best ROC AUC: {study_tree.best_value:.3f}')\n",
    "best_params = get_best_params(study_tree.best_params)\n",
    "print('\\nBest parameters:')\n",
    "pprint(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Важность признаков судя по перебору*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Самым влиятельным для модели гиперпараметром является `preprocessor__categorical_ordered__encoder`\n",
    "- Менее влиятельными, но тоже важными можно считать `preprocessor__catatigorical__encoder` и `model__estimator__splitter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_8_5_2_'></a>[Feature Engineering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Обучим модель на лучших параметрах*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv_tree = clone(pipeline).set_params(**best_params)\n",
    "rfecv_tree.fit(X_train, y_train.cat.codes)\n",
    "rfecv_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*График зависимости качества модели от количества признаков*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_perfomance(rfecv_tree.named_steps['model'].cv_results_,\n",
    "                             model_names=['Дерево решений'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv_tree.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RFECV по итогу отобрал всего 5 признаков\n",
    "- Качество на тестовой выборке составило ROC AUC = 0.880\n",
    "- Однако это модель очень нестабильна относительно признаков, на графике зависимости можно наблюдать сразу 4 пика, что говорит о возможном недообучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Интерпретация важности признаков через shap*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = rfecv_tree.transform(X_test)\n",
    "final_feature_names = np.array(rfecv_tree.get_feature_names_out())\n",
    "explainer = shap.TreeExplainer(rfecv_tree.named_steps['model'].estimator_, feature_names=final_feature_names)\n",
    "shap_values = explainer.shap_values(X_test_transformed)[:, :, 0]\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names=final_feature_names, plot_type='violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Самой влиятельной фичой является `promotional_purchases`, который обратнопропорционален таргету (что вполне логично)\n",
    "- Также влиятельными считаются признаки `pages_per_visit` (прямопропорционально) и `spent_time_prev_month` (прямопропорционально).\n",
    "- Распределение вышеперечисленных признаков равномерно и вправо, и влево, а также достаточно амплитудно, что есть хорошо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### <a id='toc1_8_6_'></a>[KNN](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_8_6_1_'></a>[Подбор гиперпараметров](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_pipepline_clf(\n",
    "    feature_selection='SelectKBest',\n",
    "    numerical_columns=market.select_dtypes(include='number').columns,\n",
    "    categorical_columns=['popular_category'],\n",
    "    categorical_ordered_columns=['service_type', 'allow_notifications']\n",
    ")\n",
    "\n",
    "model_params_cat = {'model': [KNeighborsClassifier()],\n",
    "                    'model__weights': ['uniform', 'distance']}\n",
    "model_params_num = {\n",
    "    'model__n_neighbors': lambda trial: trial.suggest_int('model__n_neighbors', 3, 100),\n",
    "    'feature_selection__k': lambda trial: trial.suggest_int('feature_selection__k', 2, X_train.shape[1]),\n",
    "}\n",
    "\n",
    "study_knn = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "study_knn.optimize(objective, n_trials=300, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best ROC AUC: {study_knn.best_value:.3f}')\n",
    "best_params = get_best_params(study_knn.best_params)\n",
    "print('\\nBest parameters:')\n",
    "pprint(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Важность признаков судя по перебору*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Наиболее значимым гиперпараметром считается `feature_selection__k`\n",
    "- Также стоит отметить вклад параметров `preprocessor__categorical_ordered__encoder`, `preprocessor__categorical_ordered__scaler` и `preprocessor__categorical__encoder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_8_6_2_'></a>[Feature Engineering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Обучим модель на лучших параметрах*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = clone(pipeline).set_params(**best_params)\n",
    "knn.fit(X_train, y_train.cat.codes)\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_perfomance(study_knn.trials_dataframe().groupby('params_feature_selection__k')['value'].max(),\n",
    "                             model_names=['KNN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC AUC на тестовой выборке составляет 0.923\n",
    "- Модель показывает лучшие результаты на 8 признаках\n",
    "- Можно заметить, что модель после пика идет по нисходящей, видимо из-за переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### <a id='toc1_8_7_'></a>[Метод опорных векторов](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_8_7_1_'></a>[Подбор гиперпараметров](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_pipepline_clf(\n",
    "    feature_selection='SelectKBest',\n",
    "    numerical_columns=market.select_dtypes(include='number').columns,\n",
    "    categorical_columns=['popular_category'],\n",
    "    categorical_ordered_columns=['service_type', 'allow_notifications']\n",
    ")\n",
    "\n",
    "model_params_cat = {'model': [SVC(random_state=RANDOM_STATE)],\n",
    "                    'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "model_params_num = {\n",
    "    'model__C': lambda trial: trial.suggest_float('model__C', 1e-3, 1e3, log=True),\n",
    "    'model__gamma': lambda trial: trial.suggest_float('model__gamma', 1e-3, 1, log=True),\n",
    "    'model__degree': lambda trial: trial.suggest_int('model__degree', 2, 4),\n",
    "    'model__coef0': lambda trial: trial.suggest_float('model__coef0', 0.0, 10.0),\n",
    "    'feature_selection__k': lambda trial: trial.suggest_int('feature_selection__k', 2, X_train.shape[1]),\n",
    "}\n",
    "\n",
    "study_svc = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "study_svc.optimize(objective, n_trials=300, show_progress_bar=True, timeout=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best ROC AUC: {study_svc.best_value:.3f}')\n",
    "best_params = get_best_params(study_svc.best_params)\n",
    "print('\\nBest parameters:')\n",
    "pprint(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_8_7_2_'></a>[Feature Engineering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Важность признаков судя по перебору*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Наиболее значимыми признакоми считаются `model__gamma`, `feature_selection__k` и `preprocessor__categorical_ordered__encoder`\n",
    "- Также стоит отметить важные признаки `preprocessor__categorical_ordered__scaler`, `preprocessor__categorical__encoder`,  `preprocessor__categorical_ordered__inputer_after`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Обучим модель на лучших параметрах*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = clone(pipeline).set_params(**best_params)\n",
    "svc.fit(X_train, y_train.cat.codes)\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_perfomance(study_svc.trials_dataframe().groupby('params_feature_selection__k')['value'].max(),\n",
    "                             model_names=['Метод опорных векторов'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Результаты топ модели на тестововой выборке составляет 0.908\n",
    "- Лучший результат модель показывает на 12 фичах, после чего модель выходит на плато."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### <a id='toc1_8_8_'></a>[Вывод](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_perfomance(rfecv_logreg.named_steps['model'].cv_results_,\n",
    "                             rfecv_tree.named_steps['model'].cv_results_,\n",
    "                             study_knn.trials_dataframe().groupby('params_feature_selection__k')['value'].max(),\n",
    "                             study_svc.trials_dataframe().groupby('params_feature_selection__k')['value'].max(),\n",
    "                             model_names=['Логистическая регрессия', 'Дерево решений', 'KNN', 'Метод опорных векторов'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Лучше всех на валидации показала себя модель KNN. Посмотрим ее качество на тестовой выборке*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ROC AUC KNN на тестовой выборки = {roc_auc_score(y_test.cat.codes, knn.predict_proba(X_test)[:, 1]):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Хороший результат, возьмем эту модель как итоговую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Отобранные моделью признаки*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.named_steps['preprocessor'].get_feature_names_out()[knn.named_steps['feature_selection'].get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### <a id='toc1_8_9_'></a>[Вывод:](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Логистическая регрессия\n",
    "- Показала стабильные результаты.\n",
    "- Лучший ROC AUC составил 0.899.\n",
    "- Логистическая регрессия показала устойчивость к уменьшению числа признаков, сохраняя высокое качество при 8 признаках.\n",
    "- Легко интерпретируемая модель, что является значимым фактором для бизнеса.\n",
    "\n",
    "2. Дерево решений\n",
    "- Продемонстрировало хороший результат (ROC AUC = 0.878) при использовании небольшого количества признаков (5).\n",
    "- Однако очень нестабильно относительно кол-ва фичей.\n",
    "\n",
    "3. K-Nearest Neighbors (KNN)\n",
    "- Достиг максимального ROC AUC 0.923 (лучший результат) + аналогичный результат и на тестовой выборке (0.921).\n",
    "- Модель легко интерпретируема, что важно для бизнеса.\n",
    "\n",
    "4. Метод опорных векторов (SVC)\n",
    "- Наивысший ROC AUC составил 0.907, однако показала менее нестабильное поведение при разном количестве признаков.\n",
    "- Модель менее интерпретируема, а качество на малом числе признаков нестабильно, что усложняет применение в реальных условиях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr style=\"border: none; border-top: 2px dashed;\">\n",
    "\n",
    "- Итоговая модель: KNN\n",
    "    \n",
    "    Выбор итоговой модели обусловлен следующими причинами:\n",
    "    - Интерпретируемость: Позволяет легко понять значимость отдельных признаков и их влияние на целевую переменную, что важно для принятия решений в бизнесе.\n",
    "    - Качество: Лучшее среди обученных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## <a id='toc1_9_'></a>[Сегментация покупателей](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для чистоты анализа возьмем тестовую выборку для анализа. Добавим в нее предсказания выбранной модели. Также добавим к нашему датасету данные из таблицы `money`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Снизилась` = 1\n",
    "- `Прежний уровень` = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = X_test.copy()\n",
    "segmentation = segmentation.merge(money, on='id')\n",
    "segmentation['probability_of_decrease'] = knn.predict_proba(X_test)[:, 1]\n",
    "segmentation['customer_activity'] = y_test.cat.codes\n",
    "market_columns_translate.update({'Прибыль': 'profit', 'Вероятность снижения покупательской активности': 'probability_of_decrease'})\n",
    "segmentation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_graphis_for_numeric(segmentation.probability_of_decrease,\n",
    "                                axis_title=market_columns_translate.inverse['probability_of_decrease'],\n",
    "                                nbinsx=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Видно, что распределение двумодельное. Второй горб описывает клиентов, склонных на снижение покупательской активности. Можно однозначно сказать, что есть явная причина, по которой часть клиентов уходят, приэтом другую часть покупателей это не задело. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_9_1_'></a>[Категории для сегментации](#toc0_)\n",
    "\n",
    "<img src=\"https://pictures.s3.yandex.net/resources/image_1695485033.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = cycle(px.colors.qualitative.Plotly)\n",
    "\n",
    "\n",
    "def pieplot_grouped_by_customer_activity(data: pd.DataFrame, column, top_n_in_pie=5):\n",
    "    \"\"\"\n",
    "    Функция для построения двух круговых диаграмм, показывающих распределение значений категориального столбца\n",
    "    для двух групп данных: с уменьшенной активностью и с сохраненной активностью.\n",
    "\n",
    "    Группировка данных происходит по значениям в колонке `customer_activity`, где:\n",
    "    - `0` — означает снижение активности.\n",
    "    - `1` — означает сохранение прежнего уровня активности.\n",
    "\n",
    "    На каждой диаграмме отображаются топ-N категорий для выбранного столбца с категорией \"Остальные\" для оставшихся значений.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Входные данные в виде DataFrame, содержащие колонку `customer_activity` и категориальный столбец `column`, для которого строятся диаграммы.\n",
    "    \n",
    "    column : str\n",
    "        Имя категориальной колонки, для которой строятся круговые диаграммы. Эта колонка должна быть частью DataFrame.\n",
    "    \n",
    "    top_n_in_pie : int, по умолчанию 5\n",
    "        Количество топ-N категорий, которые будут отображены на каждой диаграмме. Остальные категории будут объединены в одну категорию \"Остальные\".\n",
    "    \"\"\" \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2, specs=[[ {'type': 'domain'}, {'type': 'domain'}]],\n",
    "        subplot_titles=('Уровень активности снизился', 'Прежний уровень активности')\n",
    "    )\n",
    "    \n",
    "    category_agg = data[data.customer_activity == 0][column].value_counts()\n",
    "    other = [category_agg[top_n_in_pie:].sum()]\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=category_agg.head(top_n_in_pie).index.tolist() + (['Остальные'] if other[0] else []),\n",
    "               values=category_agg.head(top_n_in_pie).values.tolist() + (other if other[0] else []),\n",
    "               name='',\n",
    "               textinfo='label+percent'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    category_agg = data[data.customer_activity == 1][column].value_counts()\n",
    "    other = [category_agg[top_n_in_pie:].sum()]\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=category_agg.head(top_n_in_pie).index.tolist() + (['Остальные'] if other[0] else []),\n",
    "               values=category_agg.head(top_n_in_pie).values.tolist() + (other if other[0] else []),\n",
    "               name='',\n",
    "               textinfo='label+percent'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'Круговые диаграммы по колонке <b>{market_columns_translate.inverse[column]}</b><br>(<b>{column}</b>)',\n",
    "        title_x=0.5,\n",
    "        showlegend=True,\n",
    "        width=1200,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def histogram_grouped_by_customer_activity(data: pd.DataFrame, column, nbinsx):\n",
    "    \"\"\"\n",
    "    Функция для построения гистограмм, показывающих распределение значений числовой колонки\n",
    "    для двух групп данных: с уменьшенной активностью и с сохраненной активностью.\n",
    "\n",
    "    Группировка данных происходит по значениям в колонке `customer_activity`, где:\n",
    "    - `0` — означает снижение активности.\n",
    "    - `1` — означает сохранение прежнего уровня активности.\n",
    "\n",
    "    Строятся две гистограммы, каждая для одной из групп с указанием частоты значений для выбранного столбца.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Входные данные в виде DataFrame, содержащие колонку `customer_activity` и числовой столбец `column`, для которого строятся гистограммы.\n",
    "    \n",
    "    column : str\n",
    "        Имя числовой колонки, для которой строятся гистограммы. Эта колонка должна быть частью DataFrame.\n",
    "    \n",
    "    nbinsx : int\n",
    "        Количество корзин (бин) для гистограммы.\n",
    "    \"\"\"\n",
    "    data_class_0 = data[data.customer_activity == 0][column]\n",
    "    data_class_1 = data[data.customer_activity == 1][column]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=data_class_0,\n",
    "            name='Уровень активности снизился',\n",
    "            opacity=0.5,\n",
    "            marker=dict(color='blue'),\n",
    "            nbinsx=nbinsx\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=data_class_1,\n",
    "            name='Прежний уровень активности',\n",
    "            opacity=0.5,\n",
    "            marker=dict(color='orange'),\n",
    "            nbinsx=nbinsx\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'Гистограммы по колонке <b>{market_columns_translate.inverse[column]}</b><br>(<b>{column}</b>)',\n",
    "        xaxis_title=column,\n",
    "        yaxis_title='Частота',\n",
    "        barmode='overlay',\n",
    "        legend=dict(title=\"Класс активности\"),\n",
    "        width=900,\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def draw_scatter_between_probability_of_decrease_and(data: pd.DataFrame, num_col, cat_cols, opacity=0.4, rows=2, cols=2, height=1200, width=1200):\n",
    "    \"\"\"\n",
    "    Функция для построения диаграмм рассеяния между вероятностью снижения активности \n",
    "    и числовым столбцом, разбитым по классам категориальных признаков.\n",
    "\n",
    "    Для каждого категориального признака (из списка `cat_cols`) строится диаграмма рассеяния \n",
    "    для каждого уникального значения категории, а также линия тренда для каждой группы. \n",
    "    Также отображается общая линия тренда для всего датасета.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Входные данные в виде DataFrame, содержащие как минимум два столбца:\n",
    "        - числовой столбец `num_col`, по которому строится график.\n",
    "        - колонка с вероятностью снижения активности `probability_of_decrease`.\n",
    "        - Набор категориальных признаков для группировки.\n",
    "    \n",
    "    num_col : str\n",
    "        Имя числового столбца в DataFrame, для которого строится диаграмма рассеяния.\n",
    "\n",
    "    cat_cols : list[str]\n",
    "        Список категориальных признаков, по которым будет выполняться группировка данных \n",
    "        и строиться отдельная диаграмма рассеяния.\n",
    "\n",
    "    opacity : float, по умолчанию 0.4\n",
    "        Степень прозрачности точек на графике (от 0 до 1).\n",
    "\n",
    "    rows : int, по умолчанию 2\n",
    "        Количество строк для размещения графиков в сетке.\n",
    "\n",
    "    cols : int, по умолчанию 2\n",
    "        Количество столбцов для размещения графиков в сетке.\n",
    "\n",
    "    height : int, по умолчанию 1200\n",
    "        Высота итогового графика в пикселях.\n",
    "\n",
    "    width : int, по умолчанию 1200\n",
    "        Ширина итогового графика в пикселях.\n",
    "    \"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols, vertical_spacing=0.09,\n",
    "        subplot_titles=[market_columns_translate.inverse[col] for col in data.select_dtypes(include='object').columns]\n",
    "    )\n",
    "\n",
    "    for cetegoty_i, category_col in enumerate(cat_cols):\n",
    "        # Перебор категориальных признаков\n",
    "\n",
    "        for class_of_category, group_of_category in data.groupby(category_col):\n",
    "            # Перебор по каждому классу категории\n",
    "\n",
    "            color = next(color_palette)\n",
    "            x = group_of_category[num_col]\n",
    "            y = group_of_category['probability_of_decrease']\n",
    "\n",
    "            # диаграмма рассеяния по классу\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x,\n",
    "                    y=y,\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=7, opacity=opacity, color=color),\n",
    "                    name=class_of_category,\n",
    "                    legendgroup=market_columns_translate.inverse[category_col],\n",
    "                    legendgrouptitle=dict(text=market_columns_translate.inverse[category_col]),\n",
    "                ),\n",
    "                row=cetegoty_i // cols + 1, col=cetegoty_i % cols + 1\n",
    "            )\n",
    "            slope, intercept = np.polyfit(x, y, 1)\n",
    "            trend_line = slope * x + intercept\n",
    "\n",
    "            # Линия тренда по классу\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x,\n",
    "                    y=trend_line,\n",
    "                    mode='lines',\n",
    "                    line=dict(\n",
    "                        color=f'rgb{find_intermediate_color(hex_to_rgb(color), [0] * 3, 0.4)}',\n",
    "                        width=3\n",
    "                    ),\n",
    "                    name='Линия тренда',\n",
    "                    visible='legendonly',\n",
    "                    legendgroup=market_columns_translate.inverse[category_col],\n",
    "                ),\n",
    "                row=cetegoty_i // cols + 1, col=cetegoty_i % cols + 1\n",
    "            )\n",
    "\n",
    "        # Общая линия тренда\n",
    "        slope, intercept = np.polyfit(data[num_col], data.probability_of_decrease, 1)\n",
    "        trend_line = slope * data[num_col] + intercept\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data[num_col],\n",
    "                y=trend_line,\n",
    "                mode='lines',\n",
    "                name='Общая линия тренда',\n",
    "                visible='legendonly',\n",
    "                line=dict(color='black', width=3),\n",
    "                legendgroup=market_columns_translate.inverse[category_col],\n",
    "            ),\n",
    "            row=cetegoty_i // 2 + 1, col=cetegoty_i % 2 + 1\n",
    "        )\n",
    "        fig.update_xaxes(title_text=market_columns_translate.inverse[num_col], row=cetegoty_i // 2 + 1, col=cetegoty_i % 2 + 1)\n",
    "        fig.update_yaxes(title_text=market_columns_translate.inverse['probability_of_decrease'], row=cetegoty_i // 2 + 1, col=cetegoty_i % 2 + 1)\n",
    "\n",
    "    title=(f'Диаграммы рассеяния между признаками <b>Вероятность снижения активности</b><br>и <b>{market_columns_translate.inverse[num_col]}</b>,' +\n",
    "           f'разбитые по классам категориальных признаков<br>corr={data.probability_of_decrease.corr(data[num_col]):.3f}')\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        title_y=0.98,\n",
    "        title_x=0.5,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        legend=dict(\n",
    "            traceorder='grouped',\n",
    "            groupclick='toggleitem',\n",
    "        ),\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_9_1_1_'></a>[Коммуникация с клиентом](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communication  = segmentation[['service_type', 'allow_notifications', 'marketing_activity_6_months', 'current_month_marketing_activity', 'registration_duration', 'probability_of_decrease', 'customer_activity']]\n",
    "communication.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['service_type', 'allow_notifications', 'current_month_marketing_activity']\n",
    "for cat_col in ['service_type', 'allow_notifications', 'current_month_marketing_activity']:\n",
    "    pieplot_grouped_by_customer_activity(communication, cat_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- По круговой диаграмме `Тип сервиса` видно, что покупатальская активность снизилась больше у клиентов с типом сервиса премиум "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_col in ['marketing_activity_6_months', 'registration_duration']:\n",
    "    histogram_grouped_by_customer_activity(communication, num_col, nbinsx=20)\n",
    "    draw_scatter_between_probability_of_decrease_and(communication, num_col, cat_cols, rows=2, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- По гистограмме `Маркет_актив_6_мес` видно, что клиенты, которым было уделено меньше маркетингого привлечения, имеет спад поупательской активность (все логично)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_9_1_2_'></a>[Продуктовое поведение](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_behavior = segmentation[['popular_category', 'avg_categories_per_visit', 'unpaid_products_quarter', 'probability_of_decrease', 'customer_activity']]\n",
    "product_behavior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in ['popular_category', 'unpaid_products_quarter']:\n",
    "    pieplot_grouped_by_customer_activity(product_behavior, cat_col, top_n_in_pie=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Видно, что из-за уменьшения продаж \"Техника для красоты и здоровья\" и \"Мелкая бытовая техника и электроника\" уменьшилась и покупательская активность. Вполне возможно что уменьшение продаж этих категорий напрямую связано с уменьшением поставок, следственно некоторые клиенты купили себе товары этой категории в других магазинах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_grouped_by_customer_activity(product_behavior, 'avg_categories_per_visit', nbinsx=20)\n",
    "draw_scatter_between_probability_of_decrease_and(product_behavior, 'avg_categories_per_visit', ['popular_category', 'unpaid_products_quarter'], rows=1, height=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Гистограмма подтверждает предыдущий вывод о нехватке ассортимента на полках магазина, так как видно, что клиент просмматривает меньшее кол-во категорий, из-за нехватки продукции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_9_1_3_'></a>[Поведение на сайте](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_behavior = segmentation[\n",
    "    ['spent_time_cur_month', 'spent_time_prev_month', 'pages_per_visit', 'service_errors', 'probability_of_decrease', 'customer_activity']\n",
    "].merge((market_time.groupby('id')['minutes'].sum() / 2), on='id').rename(columns={'minutes': 'avg_minutes'})\n",
    "site_behavior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_col in ['spent_time_cur_month', 'spent_time_prev_month', 'pages_per_visit', 'service_errors']:\n",
    "    histogram_grouped_by_customer_activity(site_behavior, num_col, nbinsx=20)\n",
    "    draw_scatter_between_probability_of_decrease_and(site_behavior, num_col, ['customer_activity'], opacity=0.7, rows=1, cols=1, height=650, width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- На данных гистограммах можно отчетливо увидеть, что время, проведенное на сайте упало у клиентов с низким уровнем активности. С одной стороны это поледствие уменьшение активности, однако такую природу гистограмм можно описать и с другой стороны, к примеру: Пользователь не нашел нужных товаров, поэтому пошел искать в другой магазин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; border-top: 3px dashed;\">\n",
    "\n",
    "#### <a id='toc1_9_1_4_'></a>[Финансовое поведение](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_behavior = segmentation[['revenue_cur_month', 'probability_of_decrease', 'customer_activity']]\n",
    "financial_behavior['revenue_diff_cur_prev_month'] = X_test['revenue_cur_month'] - X_test['revenue_prev_month']\n",
    "financial_behavior['revenue_diff_prev_preprev_month'] = X_test['revenue_prev_month'] - X_test['revenue_preprev_month']\n",
    "financial_behavior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_columns_translate.update({'Разница в выручке между текущим и прошлым месяцами': 'revenue_diff_cur_prev_month', 'Разница в выручке между прошлым и позапрошлым месяцями': 'revenue_diff_prev_preprev_month'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_col in ['revenue_cur_month', 'revenue_diff_cur_prev_month', 'revenue_diff_prev_preprev_month']:\n",
    "    histogram_grouped_by_customer_activity(financial_behavior, num_col, nbinsx=40)\n",
    "    draw_scatter_between_probability_of_decrease_and(financial_behavior, num_col, ['customer_activity'], opacity=0.7, rows=1, cols=1, height=650, width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Здесь мы можем наблюдать уменьшение выручки с клиентов, покупательская активность которых падает, это не причина, а следствие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### <a id='toc1_9_2_'></a>[Вывод](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Сегментация покупателей**:\n",
    "    - Распределение вероятности снижения покупательской активности имеет двумодальное распределение, что указывает на наличие двух различных групп клиентов.\n",
    "    - Клиенты с типом сервиса \"премиум\" имеют более высокую вероятность снижения покупательской активности по сравнению с клиентами с типом сервиса \"стандарт\".\n",
    "    - Клиенты, которым было уделено меньше маркетингового внимания за последние 6 месяцев, имеют более высокую вероятность снижения покупательской активности.\n",
    "\n",
    "2. **Продуктовое поведение**:\n",
    "    - Снижение покупательской активности связано с уменьшением продаж в категориях \"Техника для красоты и здоровья\" и \"Мелкая бытовая техника и электроника\".\n",
    "    - Клиенты, которые просматривают меньшее количество категорий за визит, имеют более высокую вероятность снижения покупательской активности, что может указывать на нехватку ассортимента.\n",
    "\n",
    "3. **Поведение на сайте**:\n",
    "    - Клиенты с низким уровнем активности проводят меньше времени на сайте, что может быть как следствием, так и причиной снижения покупательской активности.\n",
    "    - У клиентов с низким уровнем активности также наблюдается меньшее количество страниц за визит и большее количество ошибок сервиса.\n",
    "\n",
    "4. **Финансовое поведение**:\n",
    "    - Снижение покупательской активности сопровождается уменьшением выручки от клиентов, что является следствием снижения их активности.\n",
    "    - Клиенты с высокой вероятностью снижения покупательской активности показывают отрицательную динамику выручки за последние месяцы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Предложения бизнесу***\n",
    "1. **Увеличение маркетинговой активности**:\n",
    "    - **Причина**: Анализ показал, что клиенты с низкой маркетинговой активностью за последние 6 месяцев имеют более высокую вероятность снижения покупательской активности.\n",
    "    - **Предложение**: Увеличить количество маркетинговых кампаний, направленных на этот сегмент клиентов, с акцентом на персонализированные предложения и скидки.\n",
    "\n",
    "2. **Оптимизация ассортимента товаров**:\n",
    "    - **Причина**: Клиенты, которые просматривают меньшее количество категорий товаров, имеют более высокую вероятность снижения покупательской активности. Это может быть связано с нехваткой интересующих их товаров.\n",
    "    - **Предложение**: Провести анализ ассортимента и увеличить наличие популярных категорий товаров, таких как \"Техника для красоты и здоровья\" и \"Мелкая бытовая техника и электроника\".\n",
    "\n",
    "3. **Улучшение пользовательского опыта на сайте**:\n",
    "    - **Причина**: Клиенты, которые проводят меньше времени на сайте и сталкиваются с ошибками сервиса, имеют более высокую вероятность снижения покупательской активности.\n",
    "    - **Предложение**: Оптимизировать работу сайта, уменьшить количество ошибок сервиса и улучшить навигацию, чтобы пользователи могли легко находить интересующие их товары.\n",
    "\n",
    "4. **Персонализированные уведомления**:\n",
    "    - **Причина**: Клиенты, которые разрешили получать уведомления, имеют более высокую вероятность снижения покупательской активности.\n",
    "    - **Предложение**: Персонализировать уведомления, чтобы они были более релевантными и интересными для клиентов, что может повысить их вовлеченность и активность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## <a id='toc1_10_'></a>[Общий вывод](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Модели**\n",
    "1. **Логистическая регрессия**:\n",
    "    - Показала стабильные результаты.\n",
    "    - Лучший ROC AUC составил 0.899.\n",
    "    - Логистическая регрессия показала устойчивость к уменьшению числа признаков, сохраняя высокое качество при 8 признаках.\n",
    "    - Легко интерпретируемая модель, что является значимым фактором для бизнеса.\n",
    "2. **Дерево решений**:\n",
    "    - Продемонстрировало хороший результат (ROC AUC = 0.881) при использовании большого количества признаков (11).\n",
    "    - Однако уступает другим моделям в стабильности качества.\n",
    "\n",
    "3. **K-Nearest Neighbors (KNN)**:\n",
    "    - Достиг максимального ROC AUC 0.923 (лучший результат)\n",
    "\n",
    "4. **Метод опорных векторов (SVC)**:\n",
    "    - Наивысший ROC AUC составил 0.910.\n",
    "    - Модель менее интерпретируема.\n",
    "\n",
    "- **KNN** была выбрана в качестве итоговой модели по следующим причинам:\n",
    "    - **Интерпретируемость**: позволяет легко понять значимость отдельных признаков и их влияние на целевую переменную, что важно для принятия решений в бизнесе.\n",
    "    - **Стабильность**: Модель высокое качество независимо от числа используемых признаков, что делает ее надежным выбором.\n",
    "    - **Качество**: С отрывом лучше остальных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Предложения бизнесу**\n",
    "1. **Увеличение маркетинговой активности**:\n",
    "    - **Причина**: Анализ показал, что клиенты с низкой маркетинговой активностью за последние 6 месяцев имеют более высокую вероятность снижения покупательской активности.\n",
    "    - **Предложение**: Увеличить количество маркетинговых кампаний, направленных на этот сегмент клиентов, с акцентом на персонализированные предложения и скидки.\n",
    "2. **Оптимизация ассортимента товаров**:\n",
    "    - **Причина**: Клиенты, которые просматривают меньшее количество категорий товаров, имеют более высокую вероятность снижения покупательской активности. Это может быть связано с нехваткой интересующих их товаров.\n",
    "    - **Предложение**: Провести анализ ассортимента и увеличить наличие популярных категорий товаров, таких как \"Техника для красоты и здоровья\" и \"Мелкая бытовая техника и электроника\".\n",
    "3. **Улучшение пользовательского опыта на сайте**:\n",
    "    - **Причина**: Клиенты, которые проводят меньше времени на сайте и сталкиваются с ошибками сервиса, имеют более высокую вероятность снижения покупательской активности.\n",
    "    - **Предложение**: Оптимизировать работу сайта, уменьшить количество ошибок сервиса и улучшить навигацию, чтобы пользователи могли легко находить интересующие их товары.\n",
    "4. **Персонализированные уведомления**:\n",
    "    - **Причина**: Клиенты, которые разрешили получать уведомления, имеют более высокую вероятность снижения покупательской активности.\n",
    "    - **Предложение**: Персонализировать уведомления, чтобы они были более релевантными и интересными для клиентов, что может повысить их вовлеченность и активность."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
